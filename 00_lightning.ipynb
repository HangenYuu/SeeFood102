{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Over the course of the project I have touched my hand at 4 models (ConvNeXt, ViT, Swin, BEiT(?)). They have all been competitive in terms of performance after fine-tuning, but they are shared the same trait: big.\n",
    "\n",
    "Now, \"size matters\" cuts both ways: larger models (tend to) have better performance, but they are always slower and requires more CPU (and GPU/TPU i.e. accelerated hardware) RAM. If you have infinite computing and processing power (e.g., 100+ NVIDIA 80GB H100s lying around), no problem. But if you are deploying your model to something else, or if latency costs you a lot of money, you are in for a big problem. You will want to reduce the size of the model while retaining as much performance as possible.\n",
    "\n",
    "My first deployment on Hugging Face Space is a Swin-Large model. It fits just fine on the space, but each prediction takes ~5.4s to carry out. I want to explore different alternatives, which may have worse performance but offer better latency."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking around"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A helpful rule of thumb I follow is: \"People have already done that.\"\n",
    "\n",
    "I always expect that whatever I can think of, people have already thought of, achieved, or come very close to. There are many reasons behind this, but the interesting corollary is that the first thing I do is looking up what people have done.\n",
    "\n",
    "I found [Jeremy Howard's visualization of `timm`'s benchmark](https://www.kaggle.com/code/jhoward/which-image-models-are-best/) and [Daniel Bourke's result with ViT and EfficientNet](https://www.learnpytorch.io/09_pytorch_model_deployment/) (and while I am at it, yes, I am following Bourke's course)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jeremy's visualization suggested that I should check out:\n",
    "- LeViT\n",
    "- ViT (okay, it was not even there - just my pick)\n",
    "- Swin\n",
    "- ConvNeXt\n",
    "- BeIT\n",
    "- EfficientNet\n",
    "\n",
    "from `timm`.\n",
    "\n",
    "And I planed to do exactly that in this notebook, with the help of Pytorch-Lightning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I want a model that is:\n",
    "- 95%++ accuracy\n",
    "- As low latency as possible, preferably close to FPS24 (the standard one for old movie with synchonized sound...)\n",
    "- As low memory as possible\n",
    "- High F1 score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specifications:\n",
    "- Dataset: Food101 (100% data)\n",
    "- Hardware: NVIDIA GeForce RTX 3090 + CUDA 11.6 + PyTorch 2.0.1\n",
    "- Batch size: 64\n",
    "- Epochs: 3\n",
    "- Optimizer: AdamW\n",
    "- Scheduler: OneCycler\n",
    "- Metrics: Accuracy, F1-Score\n",
    "- Tracking: Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union\n",
    "from pathlib import Path\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import timm\n",
    "import torch.nn as nn\n",
    "import torchmetrics\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Food101DataModule(pl.LightningDataModule):\n",
    "    def __init__(self, data_dir: Union[str, Path] = \"data\", batch_size: int = 64) -> None:\n",
    "        super().__init__()\n",
    "        self.data_dir = data_dir\n",
    "        self.batch_size = batch_size\n",
    "        self.transform = \n",
    "    \n",
    "    def \n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
